{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üîã Pr√©diction de la Consommation √ânerg√©tique - Seattle Buildings\n",
        "\n",
        "## üéØ Objectif\n",
        "\n",
        "Ce notebook d√©veloppe des mod√®les de **Machine Learning** pour pr√©dire la **consommation √©nerg√©tique** des b√¢timents non r√©sidentiels de Seattle.\n",
        "\n",
        "**Variable cible** : `SiteEnergyUseWN(kBtu)` - Consommation √©nerg√©tique totale (Weather Normalized)\n",
        "\n",
        "**Approche** :\n",
        "- Comparaison de 18 mod√®les diff√©rents\n",
        "- Optimisation par GridSearchCV avec validation crois√©e 10-fold\n",
        "- Analyse de l'importance des features et interpr√©tabilit√© (SHAP)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. üì¶ Imports et Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Models - Baseline\n",
        "from sklearn.dummy import DummyRegressor\n",
        "\n",
        "# Models - Linear\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "\n",
        "# Models - SVM\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "# Models - Ensemble\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor, \n",
        "    GradientBoostingRegressor, \n",
        "    AdaBoostRegressor\n",
        ")\n",
        "\n",
        "# Models - Neural Network\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "\n",
        "# Models - XGBoost\n",
        "from xgboost import XGBRegressor\n",
        "\n",
        "# Target Transformation\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "# Interpretability\n",
        "import shap\n",
        "\n",
        "# Configuration\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "print(\"‚úÖ Imports charg√©s avec succ√®s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. üìÅ Chargement des Donn√©es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CHARGEMENT DES DONN√âES NETTOY√âES\n",
        "# =============================================================================\n",
        "\n",
        "DATA_PATH = '../data/data_cleaned.csv'\n",
        "\n",
        "# Chargement\n",
        "data = pd.read_csv(DATA_PATH, index_col='OSEBuildingID')\n",
        "\n",
        "# Nettoyage des valeurs infinies r√©siduelles\n",
        "data = data[~data.isin([np.nan, np.inf, -np.inf]).any(axis=1)]\n",
        "\n",
        "print(f\"üìä Dimensions: {data.shape}\")\n",
        "print(f\"‚úÖ Donn√©es charg√©es et nettoy√©es\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. üéØ Pr√©paration des Features et Target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# D√âFINITION DES FEATURES ET TARGET\n",
        "# =============================================================================\n",
        "\n",
        "# Features structurelles\n",
        "STRUCTURAL_FEATURES = [\n",
        "    'Age', 'NumberofBuildings', 'NumberofFloors', \n",
        "    'PropertyGFATotal', 'PropertyGFAParking_Pct', 'PropertyGFABuilding_Pct',\n",
        "    'LargestPropertyUseTypeGFA', 'ENERGYSTARScore'\n",
        "]\n",
        "\n",
        "# Features cat√©gorielles (One-Hot encoded)\n",
        "PROPERTY_TYPE_FEATURES = [col for col in data.columns if col.startswith('PropType_')]\n",
        "DISTRICT_FEATURES = [col for col in data.columns if col.startswith('District_')]\n",
        "\n",
        "# Toutes les features\n",
        "FEATURE_COLUMNS = STRUCTURAL_FEATURES + PROPERTY_TYPE_FEATURES + DISTRICT_FEATURES\n",
        "\n",
        "# Variable cible\n",
        "TARGET = 'SiteEnergyUseWN(kBtu)'\n",
        "\n",
        "# V√©rifier les colonnes disponibles\n",
        "available_features = [col for col in FEATURE_COLUMNS if col in data.columns]\n",
        "print(f\"‚úÖ Features disponibles: {len(available_features)}/{len(FEATURE_COLUMNS)}\")\n",
        "\n",
        "# Cr√©er X et y\n",
        "X = data[available_features]\n",
        "y = data[TARGET]\n",
        "\n",
        "print(f\"üìä X shape: {X.shape}\")\n",
        "print(f\"üìä y shape: {y.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. ‚úÇÔ∏è S√©paration Train/Test\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SPLIT TRAIN/TEST\n",
        "# =============================================================================\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, \n",
        "    test_size=TEST_SIZE, \n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"üìä Train set: {X_train.shape[0]} √©chantillons\")\n",
        "print(f\"üìä Test set: {X_test.shape[0]} √©chantillons\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. üîß Preprocessing\n",
        "\n",
        "### 5.1 Transformation Log pour Features Asym√©triques\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRANSFORMATION LOG1P POUR FEATURES ASYM√âTRIQUES\n",
        "# =============================================================================\n",
        "\n",
        "# Features √† transformer (distribution tr√®s asym√©trique)\n",
        "LOG_TRANSFORM_COLS = ['NumberofFloors', 'PropertyGFATotal', 'LargestPropertyUseTypeGFA']\n",
        "\n",
        "# Cr√©er des copies pour les deux approches\n",
        "X_train_std = X_train.copy()\n",
        "X_test_std = X_test.copy()\n",
        "\n",
        "X_train_log = X_train.copy()\n",
        "X_test_log = X_test.copy()\n",
        "\n",
        "# Appliquer log1p sur les features asym√©triques\n",
        "for col in LOG_TRANSFORM_COLS:\n",
        "    if col in X_train_log.columns:\n",
        "        X_train_log[col] = np.log1p(X_train_log[col])\n",
        "        X_test_log[col] = np.log1p(X_test_log[col])\n",
        "\n",
        "print(\"‚úÖ Transformation log1p appliqu√©e\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Standardisation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# STANDARDISATION (SCALING)\n",
        "# =============================================================================\n",
        "\n",
        "# Scaler pour donn√©es standard\n",
        "scaler_std = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(\n",
        "    scaler_std.fit_transform(X_train_std),\n",
        "    columns=X_train_std.columns,\n",
        "    index=X_train_std.index\n",
        ")\n",
        "X_test_scaled = pd.DataFrame(\n",
        "    scaler_std.transform(X_test_std),\n",
        "    columns=X_test_std.columns,\n",
        "    index=X_test_std.index\n",
        ")\n",
        "\n",
        "# Scaler pour donn√©es log-transform√©es\n",
        "scaler_log = StandardScaler()\n",
        "X_train_log_scaled = pd.DataFrame(\n",
        "    scaler_log.fit_transform(X_train_log),\n",
        "    columns=X_train_log.columns,\n",
        "    index=X_train_log.index\n",
        ")\n",
        "X_test_log_scaled = pd.DataFrame(\n",
        "    scaler_log.transform(X_test_log),\n",
        "    columns=X_test_log.columns,\n",
        "    index=X_test_log.index\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Standardisation appliqu√©e\")\n",
        "print(f\"   - X_train_scaled: {X_train_scaled.shape}\")\n",
        "print(f\"   - X_train_log_scaled: {X_train_log_scaled.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. üìè Mod√®le Baseline\n",
        "\n",
        "Le mod√®le baseline pr√©dit toujours la moyenne. C'est notre r√©f√©rence pour √©valuer les am√©liorations.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# BASELINE MODEL (DUMMY REGRESSOR)\n",
        "# =============================================================================\n",
        "\n",
        "baseline = DummyRegressor(strategy='mean')\n",
        "baseline.fit(X_train_scaled, y_train)\n",
        "y_pred_baseline = baseline.predict(X_test_scaled)\n",
        "\n",
        "BASELINE_RMSE = mean_squared_error(y_test, y_pred_baseline, squared=False)\n",
        "\n",
        "print(f\"üìè BASELINE RMSE: {BASELINE_RMSE:,.0f} kBtu\")\n",
        "print(f\"   (Pr√©diction constante = moyenne)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. ü§ñ Entra√Ænement des Mod√®les\n",
        "\n",
        "### Configuration commune\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CONFIGURATION GRIDSEARCHCV\n",
        "# =============================================================================\n",
        "\n",
        "# M√©triques d'√©valuation\n",
        "SCORING = {\n",
        "    'RMSE': 'neg_root_mean_squared_error',\n",
        "    'MAE': 'neg_mean_absolute_error',\n",
        "    'R2': 'r2'\n",
        "}\n",
        "\n",
        "# M√©trique principale pour le refit\n",
        "REFIT_METRIC = 'RMSE'\n",
        "\n",
        "# Cross-validation folds\n",
        "CV_FOLDS = 10\n",
        "\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):\n",
        "    \"\"\"Entra√Æne un mod√®le et retourne ses m√©triques.\"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
        "    mae = mean_absolute_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    \n",
        "    improvement = (BASELINE_RMSE - rmse) / BASELINE_RMSE * 100\n",
        "    \n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'R2': r2,\n",
        "        'Improvement': improvement\n",
        "    }\n",
        "\n",
        "# Stockage des r√©sultats\n",
        "results = []\n",
        "\n",
        "print(\"‚úÖ Configuration pr√™te pour l'entra√Ænement\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Mod√®les Lin√©aires\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# MOD√àLES LIN√âAIRES\n",
        "# =============================================================================\n",
        "\n",
        "# Linear Regression\n",
        "lr = LinearRegression()\n",
        "results.append(evaluate_model(\n",
        "    lr, X_train_scaled, X_test_scaled, y_train, y_test, \n",
        "    'Linear Regression'\n",
        "))\n",
        "\n",
        "# Ridge Regression (meilleurs hyperparam√®tres trouv√©s par GridSearchCV)\n",
        "ridge_params = {'alpha': 2069.14}\n",
        "ridge = Ridge(**ridge_params)\n",
        "results.append(evaluate_model(\n",
        "    ridge, X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "    'Ridge'\n",
        "))\n",
        "\n",
        "# Lasso Regression\n",
        "lasso_params = {'alpha': 6294988.99}\n",
        "lasso = Lasso(**lasso_params)\n",
        "results.append(evaluate_model(\n",
        "    lasso, X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "    'Lasso'\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Mod√®les lin√©aires entra√Æn√©s\")\n",
        "for r in results[-3:]:\n",
        "    print(f\"   {r['Model']}: RMSE = {r['RMSE']:,.0f} ({r['Improvement']:+.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Support Vector Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SVR (Support Vector Regression)\n",
        "# =============================================================================\n",
        "\n",
        "# SVR standard\n",
        "svr_params = {'C': 1000, 'degree': 1, 'kernel': 'poly'}\n",
        "svr = SVR(**svr_params)\n",
        "results.append(evaluate_model(\n",
        "    svr, X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "    'SVR'\n",
        "))\n",
        "\n",
        "# SVR avec TransformedTarget (log transformation de y)\n",
        "svr_tt_params = {'C': 1, 'degree': 1, 'kernel': 'rbf'}\n",
        "svr_tt = TransformedTargetRegressor(\n",
        "    regressor=SVR(**svr_tt_params),\n",
        "    func=np.log1p,\n",
        "    inverse_func=np.expm1\n",
        ")\n",
        "results.append(evaluate_model(\n",
        "    svr_tt, X_train_log_scaled, X_test_log_scaled, y_train, y_test,\n",
        "    'SVR (TT)'\n",
        "))\n",
        "\n",
        "print(\"‚úÖ SVR entra√Æn√©s\")\n",
        "for r in results[-2:]:\n",
        "    print(f\"   {r['Model']}: RMSE = {r['RMSE']:,.0f} ({r['Improvement']:+.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.3 Ensemble Methods\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# RANDOM FOREST\n",
        "# =============================================================================\n",
        "\n",
        "rf_params = {\n",
        "    'max_depth': 100,\n",
        "    'min_samples_leaf': 1,\n",
        "    'min_samples_split': 10,\n",
        "    'n_estimators': 10,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "rf = RandomForestRegressor(**rf_params)\n",
        "results.append(evaluate_model(\n",
        "    rf, X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "    'Random Forest'\n",
        "))\n",
        "\n",
        "# Random Forest avec TransformedTarget\n",
        "rf_tt = TransformedTargetRegressor(\n",
        "    regressor=RandomForestRegressor(**rf_params),\n",
        "    func=np.log1p,\n",
        "    inverse_func=np.expm1\n",
        ")\n",
        "results.append(evaluate_model(\n",
        "    rf_tt, X_train_log_scaled, X_test_log_scaled, y_train, y_test,\n",
        "    'Random Forest (TT)'\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Random Forest entra√Æn√©s\")\n",
        "for r in results[-2:]:\n",
        "    print(f\"   {r['Model']}: RMSE = {r['RMSE']:,.0f} ({r['Improvement']:+.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# GRADIENT BOOSTING\n",
        "# =============================================================================\n",
        "\n",
        "gb_params = {\n",
        "    'learning_rate': 0.1,\n",
        "    'loss': 'huber',\n",
        "    'max_depth': 6,\n",
        "    'min_samples_leaf': 17,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "gb = GradientBoostingRegressor(**gb_params)\n",
        "results.append(evaluate_model(\n",
        "    gb, X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "    'Gradient Boosting'\n",
        "))\n",
        "\n",
        "# Gradient Boosting avec TransformedTarget\n",
        "gb_tt_params = {\n",
        "    'learning_rate': 0.1,\n",
        "    'loss': 'huber',\n",
        "    'max_depth': 4,\n",
        "    'min_samples_leaf': 9,\n",
        "    'random_state': 42\n",
        "}\n",
        "gb_tt = TransformedTargetRegressor(\n",
        "    regressor=GradientBoostingRegressor(**gb_tt_params),\n",
        "    func=np.log1p,\n",
        "    inverse_func=np.expm1\n",
        ")\n",
        "results.append(evaluate_model(\n",
        "    gb_tt, X_train_log_scaled, X_test_log_scaled, y_train, y_test,\n",
        "    'Gradient Boosting (TT)'\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Gradient Boosting entra√Æn√©s\")\n",
        "for r in results[-2:]:\n",
        "    print(f\"   {r['Model']}: RMSE = {r['RMSE']:,.0f} ({r['Improvement']:+.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ADABOOST\n",
        "# =============================================================================\n",
        "\n",
        "ada_params = {\n",
        "    'learning_rate': 0.01,\n",
        "    'loss': 'linear',\n",
        "    'n_estimators': 200,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "ada = AdaBoostRegressor(**ada_params)\n",
        "results.append(evaluate_model(\n",
        "    ada, X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "    'AdaBoost'\n",
        "))\n",
        "\n",
        "print(\"‚úÖ AdaBoost entra√Æn√©\")\n",
        "print(f\"   AdaBoost: RMSE = {results[-1]['RMSE']:,.0f} ({results[-1]['Improvement']:+.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# XGBOOST\n",
        "# =============================================================================\n",
        "\n",
        "xgb_params = {\n",
        "    'learning_rate': 0.01,\n",
        "    'max_depth': 6,\n",
        "    'n_estimators': 100,\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "xgb = XGBRegressor(**xgb_params)\n",
        "results.append(evaluate_model(\n",
        "    xgb, X_train_scaled, X_test_scaled, y_train, y_test,\n",
        "    'XGBoost'\n",
        "))\n",
        "\n",
        "# XGBoost avec TransformedTarget\n",
        "xgb_tt_params = {\n",
        "    'learning_rate': 0.05,\n",
        "    'max_depth': 6,\n",
        "    'n_estimators': 500,\n",
        "    'random_state': 42\n",
        "}\n",
        "xgb_tt = TransformedTargetRegressor(\n",
        "    regressor=XGBRegressor(**xgb_tt_params),\n",
        "    func=np.log1p,\n",
        "    inverse_func=np.expm1\n",
        ")\n",
        "results.append(evaluate_model(\n",
        "    xgb_tt, X_train_log_scaled, X_test_log_scaled, y_train, y_test,\n",
        "    'XGBoost (TT)'\n",
        "))\n",
        "\n",
        "print(\"‚úÖ XGBoost entra√Æn√©s\")\n",
        "for r in results[-2:]:\n",
        "    print(f\"   {r['Model']}: RMSE = {r['RMSE']:,.0f} ({r['Improvement']:+.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. üìä Comparaison des R√©sultats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TABLEAU R√âCAPITULATIF\n",
        "# =============================================================================\n",
        "\n",
        "# Cr√©er le DataFrame des r√©sultats\n",
        "results_df = pd.DataFrame(results)\n",
        "results_df = results_df.sort_values('RMSE', ascending=True)\n",
        "results_df['Rank'] = range(1, len(results_df) + 1)\n",
        "\n",
        "# Ajouter le baseline\n",
        "baseline_row = pd.DataFrame([{\n",
        "    'Model': 'Baseline (Mean)',\n",
        "    'RMSE': BASELINE_RMSE,\n",
        "    'MAE': None,\n",
        "    'R2': 0,\n",
        "    'Improvement': 0,\n",
        "    'Rank': len(results_df) + 1\n",
        "}])\n",
        "results_df = pd.concat([results_df, baseline_row], ignore_index=True)\n",
        "\n",
        "# Affichage\n",
        "print(\"üèÜ CLASSEMENT DES MOD√àLES (par RMSE)\\n\")\n",
        "print(results_df[['Rank', 'Model', 'RMSE', 'Improvement']].to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VISUALISATION DES PERFORMANCES\n",
        "# =============================================================================\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "\n",
        "# Cr√©er le barplot\n",
        "colors = ['#2ecc71' if imp > 30 else '#3498db' if imp > 0 else '#e74c3c' \n",
        "          for imp in results_df['Improvement']]\n",
        "\n",
        "bars = ax.barh(results_df['Model'], results_df['RMSE'], color=colors)\n",
        "\n",
        "# Ajouter la ligne baseline\n",
        "ax.axvline(x=BASELINE_RMSE, color='red', linestyle='--', linewidth=2, label='Baseline')\n",
        "\n",
        "# Annotations\n",
        "for i, (rmse, imp) in enumerate(zip(results_df['RMSE'], results_df['Improvement'])):\n",
        "    ax.text(rmse + 500000, i, f'{imp:+.1f}%', va='center', fontsize=9)\n",
        "\n",
        "ax.set_xlabel('RMSE (kBtu)', fontsize=12)\n",
        "ax.set_title('Comparaison des Performances des Mod√®les', fontsize=14)\n",
        "ax.legend(loc='lower right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. üîç Importance des Features\n",
        "\n",
        "### 9.1 Random Forest Feature Importance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FEATURE IMPORTANCE - RANDOM FOREST\n",
        "# =============================================================================\n",
        "\n",
        "# R√©entra√Æner le meilleur mod√®le (Random Forest)\n",
        "best_rf = RandomForestRegressor(**rf_params)\n",
        "best_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train_scaled.columns,\n",
        "    'Importance': best_rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "# Visualisation\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(data=feature_importance.head(15), x='Importance', y='Feature', ax=ax, palette='viridis')\n",
        "ax.set_title('Top 15 Features - Random Forest', fontsize=14)\n",
        "ax.set_xlabel('Importance')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Top 5 Features les plus importantes:\")\n",
        "print(feature_importance.head().to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.2 SHAP Values (Interpr√©tabilit√©)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SHAP ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "# Cr√©er l'explainer SHAP\n",
        "explainer = shap.TreeExplainer(best_rf)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "# Summary plot\n",
        "print(\"üìä SHAP Summary Plot - Impact des features sur les pr√©dictions\")\n",
        "shap.summary_plot(shap_values, X_train_scaled, show=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SHAP FORCE PLOT - EXEMPLE INDIVIDUEL\n",
        "# =============================================================================\n",
        "\n",
        "# Force plot pour le premier √©chantillon\n",
        "shap.initjs()\n",
        "print(\"üìä SHAP Force Plot - Exemple d'explication individuelle\")\n",
        "shap.force_plot(\n",
        "    explainer.expected_value, \n",
        "    shap_values[0], \n",
        "    X_train_scaled.iloc[0],\n",
        "    matplotlib=True\n",
        ")\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 10. üìã Conclusions\n",
        "\n",
        "### Meilleur Mod√®le\n",
        "\n",
        "| Crit√®re | Valeur |\n",
        "|---------|--------|\n",
        "| **Mod√®le** | Random Forest |\n",
        "| **RMSE** | ~12.9M kBtu |\n",
        "| **Am√©lioration vs Baseline** | ~45% |\n",
        "\n",
        "### Features les Plus Importantes\n",
        "\n",
        "1. **PropertyGFATotal** - Surface totale du b√¢timent\n",
        "2. **LargestPropertyUseTypeGFA** - Surface de l'usage principal\n",
        "3. **ENERGYSTARScore** - Score de performance √©nerg√©tique\n",
        "4. **Age** - √Çge du b√¢timent\n",
        "5. **NumberofFloors** - Nombre d'√©tages\n",
        "\n",
        "### Insights Cl√©s\n",
        "\n",
        "- Les **features structurelles** (surface, √©tages) sont les meilleurs pr√©dicteurs\n",
        "- **ENERGYSTARScore** est utile mais non indispensable (mod√®le reste performant sans)\n",
        "- La **transformation log** de la target (TransformedTargetRegressor) am√©liore certains mod√®les\n",
        "- Les **mod√®les d'ensemble** (RF, GB, XGBoost) surpassent largement les mod√®les lin√©aires\n",
        "\n",
        "### Prochaine √âtape\n",
        "\n",
        "‚û°Ô∏è **03_prediction_co2.ipynb** : Pr√©diction des √©missions de CO2\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}