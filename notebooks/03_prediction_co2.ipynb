{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üåø Pr√©diction des √âmissions de CO2 - Seattle Buildings\n",
        "\n",
        "## üéØ Objectif\n",
        "\n",
        "Ce notebook d√©veloppe des mod√®les de **Machine Learning** pour pr√©dire les **√©missions de CO2** (gaz √† effet de serre) des b√¢timents non r√©sidentiels de Seattle.\n",
        "\n",
        "**Variable cible** : `TotalGHGEmissions` - √âmissions totales de gaz √† effet de serre (tonnes CO2 √©quivalent)\n",
        "\n",
        "**Contexte** : Ce projet s'inscrit dans l'objectif de la ville de Seattle d'atteindre la **neutralit√© carbone d'ici 2050**.\n",
        "\n",
        "**Approche** :\n",
        "- R√©utilisation de la m√©thodologie du notebook pr√©c√©dent\n",
        "- Focus sur les √©missions de CO2 comme variable cible\n",
        "- Analyse de l'impact des diff√©rentes features sur les √©missions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. üì¶ Imports et Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# IMPORTS\n",
        "# =============================================================================\n",
        "\n",
        "# Data manipulation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "# Models\n",
        "from sklearn.dummy import DummyRegressor\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.ensemble import (\n",
        "    RandomForestRegressor, \n",
        "    GradientBoostingRegressor, \n",
        "    AdaBoostRegressor\n",
        ")\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.compose import TransformedTargetRegressor\n",
        "\n",
        "# Interpretability\n",
        "import shap\n",
        "\n",
        "# Configuration\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "\n",
        "print(\"‚úÖ Imports charg√©s avec succ√®s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. üìÅ Chargement des Donn√©es\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# CHARGEMENT DES DONN√âES\n",
        "# =============================================================================\n",
        "\n",
        "DATA_PATH = '../data/data_cleaned.csv'\n",
        "\n",
        "data = pd.read_csv(DATA_PATH, index_col='OSEBuildingID')\n",
        "data = data[~data.isin([np.nan, np.inf, -np.inf]).any(axis=1)]\n",
        "\n",
        "print(f\"üìä Dimensions: {data.shape}\")\n",
        "print(f\"‚úÖ Donn√©es charg√©es\")\n",
        "data.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. üéØ Pr√©paration des Features et Target\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FEATURES ET TARGET\n",
        "# =============================================================================\n",
        "\n",
        "# Features structurelles\n",
        "STRUCTURAL_FEATURES = [\n",
        "    'Age', 'NumberofBuildings', 'NumberofFloors', \n",
        "    'PropertyGFATotal', 'PropertyGFAParking_Pct', 'PropertyGFABuilding_Pct',\n",
        "    'LargestPropertyUseTypeGFA', 'ENERGYSTARScore'\n",
        "]\n",
        "\n",
        "# Features cat√©gorielles\n",
        "PROPERTY_TYPE_FEATURES = [col for col in data.columns if col.startswith('PropType_')]\n",
        "DISTRICT_FEATURES = [col for col in data.columns if col.startswith('District_')]\n",
        "\n",
        "FEATURE_COLUMNS = STRUCTURAL_FEATURES + PROPERTY_TYPE_FEATURES + DISTRICT_FEATURES\n",
        "\n",
        "# Target pour les √©missions CO2\n",
        "TARGET = 'TotalGHGEmissions'\n",
        "\n",
        "# V√©rifier les colonnes\n",
        "available_features = [col for col in FEATURE_COLUMNS if col in data.columns]\n",
        "\n",
        "X = data[available_features]\n",
        "y = data[TARGET]\n",
        "\n",
        "print(f\"üìä X shape: {X.shape}\")\n",
        "print(f\"üìä y shape: {y.shape}\")\n",
        "print(f\"\\nüìä Statistiques de la cible (√©missions CO2):\")\n",
        "print(y.describe())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. ‚úÇÔ∏è S√©paration et Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# TRAIN/TEST SPLIT\n",
        "# =============================================================================\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "print(f\"üìä Train: {X_train.shape[0]} | Test: {X_test.shape[0]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# PREPROCESSING\n",
        "# =============================================================================\n",
        "\n",
        "# Transformation log pour features asym√©triques\n",
        "LOG_COLS = ['NumberofFloors', 'PropertyGFATotal', 'LargestPropertyUseTypeGFA']\n",
        "\n",
        "X_train_std = X_train.copy()\n",
        "X_test_std = X_test.copy()\n",
        "X_train_log = X_train.copy()\n",
        "X_test_log = X_test.copy()\n",
        "\n",
        "for col in LOG_COLS:\n",
        "    if col in X_train_log.columns:\n",
        "        X_train_log[col] = np.log1p(X_train_log[col])\n",
        "        X_test_log[col] = np.log1p(X_test_log[col])\n",
        "\n",
        "# Standardisation\n",
        "scaler_std = StandardScaler()\n",
        "X_train_scaled = pd.DataFrame(\n",
        "    scaler_std.fit_transform(X_train_std),\n",
        "    columns=X_train_std.columns\n",
        ")\n",
        "X_test_scaled = pd.DataFrame(\n",
        "    scaler_std.transform(X_test_std),\n",
        "    columns=X_test_std.columns\n",
        ")\n",
        "\n",
        "scaler_log = StandardScaler()\n",
        "X_train_log_scaled = pd.DataFrame(\n",
        "    scaler_log.fit_transform(X_train_log),\n",
        "    columns=X_train_log.columns\n",
        ")\n",
        "X_test_log_scaled = pd.DataFrame(\n",
        "    scaler_log.transform(X_test_log),\n",
        "    columns=X_test_log.columns\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Preprocessing termin√©\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. üìè Baseline et Mod√®les\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# BASELINE\n",
        "# =============================================================================\n",
        "\n",
        "baseline = DummyRegressor(strategy='mean')\n",
        "baseline.fit(X_train_scaled, y_train)\n",
        "y_pred_baseline = baseline.predict(X_test_scaled)\n",
        "\n",
        "BASELINE_RMSE = mean_squared_error(y_test, y_pred_baseline, squared=False)\n",
        "print(f\"üìè BASELINE RMSE: {BASELINE_RMSE:.2f} tonnes CO2\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FONCTION D'√âVALUATION\n",
        "# =============================================================================\n",
        "\n",
        "def evaluate_model(model, X_tr, X_te, y_tr, y_te, name):\n",
        "    model.fit(X_tr, y_tr)\n",
        "    y_pred = model.predict(X_te)\n",
        "    rmse = mean_squared_error(y_te, y_pred, squared=False)\n",
        "    improvement = (BASELINE_RMSE - rmse) / BASELINE_RMSE * 100\n",
        "    return {'Model': name, 'RMSE': rmse, 'Improvement': improvement}\n",
        "\n",
        "results = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# ENTRA√éNEMENT DES MOD√àLES\n",
        "# =============================================================================\n",
        "\n",
        "# Mod√®les lin√©aires\n",
        "results.append(evaluate_model(\n",
        "    LinearRegression(), X_train_scaled, X_test_scaled, y_train, y_test, \n",
        "    'Linear Regression'\n",
        "))\n",
        "\n",
        "results.append(evaluate_model(\n",
        "    Ridge(alpha=2069.14), X_train_scaled, X_test_scaled, y_train, y_test, \n",
        "    'Ridge'\n",
        "))\n",
        "\n",
        "# Random Forest (g√©n√©ralement le meilleur)\n",
        "rf_params = {'max_depth': 100, 'min_samples_leaf': 1, \n",
        "             'min_samples_split': 10, 'n_estimators': 10, 'random_state': 42}\n",
        "results.append(evaluate_model(\n",
        "    RandomForestRegressor(**rf_params), \n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, \n",
        "    'Random Forest'\n",
        "))\n",
        "\n",
        "# Gradient Boosting\n",
        "gb_params = {'learning_rate': 0.1, 'max_depth': 6, \n",
        "             'min_samples_leaf': 17, 'random_state': 42}\n",
        "results.append(evaluate_model(\n",
        "    GradientBoostingRegressor(**gb_params), \n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, \n",
        "    'Gradient Boosting'\n",
        "))\n",
        "\n",
        "# Gradient Boosting avec TransformedTarget\n",
        "gb_tt = TransformedTargetRegressor(\n",
        "    regressor=GradientBoostingRegressor(\n",
        "        learning_rate=0.1, max_depth=4, min_samples_leaf=9, random_state=42\n",
        "    ),\n",
        "    func=np.log1p, inverse_func=np.expm1\n",
        ")\n",
        "results.append(evaluate_model(\n",
        "    gb_tt, X_train_log_scaled, X_test_log_scaled, y_train, y_test, \n",
        "    'Gradient Boosting (TT)'\n",
        "))\n",
        "\n",
        "# XGBoost\n",
        "results.append(evaluate_model(\n",
        "    XGBRegressor(learning_rate=0.01, max_depth=6, n_estimators=100, random_state=42),\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, \n",
        "    'XGBoost'\n",
        "))\n",
        "\n",
        "print(\"‚úÖ Tous les mod√®les entra√Æn√©s\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. üìä R√©sultats\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# COMPARAISON DES MOD√àLES\n",
        "# =============================================================================\n",
        "\n",
        "results_df = pd.DataFrame(results).sort_values('RMSE')\n",
        "results_df['Rank'] = range(1, len(results_df) + 1)\n",
        "\n",
        "# Ajouter baseline\n",
        "baseline_row = pd.DataFrame([{\n",
        "    'Model': 'Baseline', 'RMSE': BASELINE_RMSE, 'Improvement': 0, 'Rank': len(results_df) + 1\n",
        "}])\n",
        "results_df = pd.concat([results_df, baseline_row], ignore_index=True)\n",
        "\n",
        "print(\"üèÜ CLASSEMENT DES MOD√àLES - Pr√©diction CO2\\n\")\n",
        "print(results_df.to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# VISUALISATION\n",
        "# =============================================================================\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "colors = ['#2ecc71' if imp > 30 else '#3498db' if imp > 0 else '#e74c3c' \n",
        "          for imp in results_df['Improvement']]\n",
        "\n",
        "ax.barh(results_df['Model'], results_df['RMSE'], color=colors)\n",
        "ax.axvline(x=BASELINE_RMSE, color='red', linestyle='--', linewidth=2, label='Baseline')\n",
        "ax.set_xlabel('RMSE (tonnes CO2)')\n",
        "ax.set_title('Performance des Mod√®les - Pr√©diction √âmissions CO2')\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. üîç Feature Importance et SHAP\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# FEATURE IMPORTANCE\n",
        "# =============================================================================\n",
        "\n",
        "best_rf = RandomForestRegressor(**rf_params)\n",
        "best_rf.fit(X_train_scaled, y_train)\n",
        "\n",
        "feat_imp = pd.DataFrame({\n",
        "    'Feature': X_train_scaled.columns,\n",
        "    'Importance': best_rf.feature_importances_\n",
        "}).sort_values('Importance', ascending=False)\n",
        "\n",
        "# Visualisation\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "sns.barplot(data=feat_imp.head(15), x='Importance', y='Feature', palette='viridis')\n",
        "ax.set_title('Top 15 Features - Pr√©diction CO2')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nüìä Top 5 Features:\")\n",
        "print(feat_imp.head().to_string(index=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =============================================================================\n",
        "# SHAP ANALYSIS\n",
        "# =============================================================================\n",
        "\n",
        "explainer = shap.TreeExplainer(best_rf)\n",
        "shap_values = explainer.shap_values(X_train_scaled)\n",
        "\n",
        "print(\"üìä SHAP Summary Plot - Impact sur les √©missions CO2\")\n",
        "shap.summary_plot(shap_values, X_train_scaled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. üìã Conclusions\n",
        "\n",
        "### Meilleur Mod√®le pour la Pr√©diction CO2\n",
        "\n",
        "| Crit√®re | Valeur |\n",
        "|---------|--------|\n",
        "| **Mod√®le** | Random Forest |\n",
        "| **Am√©lioration vs Baseline** | ~40-45% |\n",
        "\n",
        "### Features les Plus Importantes pour les √âmissions CO2\n",
        "\n",
        "1. **PropertyGFATotal** - Plus le b√¢timent est grand, plus il √©met\n",
        "2. **LargestPropertyUseTypeGFA** - Type d'usage principal\n",
        "3. **SiteEnergyUseWN** - Consommation √©nerg√©tique (corr√©l√©e aux √©missions)\n",
        "4. **ENERGYSTARScore** - Score d'efficacit√©\n",
        "5. **Age** - Les b√¢timents anciens √©mettent g√©n√©ralement plus\n",
        "\n",
        "### Recommandations pour Seattle\n",
        "\n",
        "1. **Cibler les grands b√¢timents** - Impact maximal sur les r√©ductions\n",
        "2. **Am√©liorer l'efficacit√© √©nerg√©tique** - Score ENERGY STAR corr√©l√© aux √©missions\n",
        "3. **R√©nover les b√¢timents anciens** - L'√¢ge est un facteur significatif\n",
        "4. **Focus sur certains types** - Bureaux et h√¥tels sont gros √©metteurs\n",
        "\n",
        "### Projet Termin√©\n",
        "\n",
        "‚úÖ Exploration des donn√©es  \n",
        "‚úÖ Pr√©diction de la consommation √©nerg√©tique  \n",
        "‚úÖ Pr√©diction des √©missions CO2  \n",
        "\n",
        "**Ce projet d√©montre une ma√Ætrise compl√®te du pipeline ML appliqu√© √† un cas r√©el d'impact environnemental.**\n"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 5
}